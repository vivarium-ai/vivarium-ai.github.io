---
title: "Part 1: The Agents"
author: Brian Shirai
date: 2025-11-05
order: 1
---

Posts in this series:

* [The Vivarium AI Experimentation Platform](/blog/2025-11-05-the-vivarium-ai-experimentation-platform/)
* [Part 1: The Agents](/blog/2025-11-05-part-1-the-agents/)
* [Part 2: The Languages](/blog/2025-11-05-part-2-the-languages/)
* [Part 3: The Tools](/blog/2025-11-05-part-3-the-tools/)
* [Part 4: The Infrastructure](/blog/2025-11-05-part-4-the-infrastructure/)
* [Part 5: The Roadmap](/blog/2025-11-05-part-5-the-roadmap/)

## AI Agents

Artificial machine intelligence, and indeed, artificial "general" intelligence, is the core concept that binds the rest of these efforts.

The language and language-related tools (e.g. the compiler assembly, including the JIT machinery) are obviously useful in a stand-alone manner because languages and compilers have been used to build many kinds of applications.

But since general purpose languages are so useful, most programmers don't consider language tools to be that useful. They have something "good enough" in the general purpose language they use for primarily the domain they work with (roughly: Ruby for webapps, Python for data science, numerical computing, and AI models, Go for networked distributed systems, Rust for "systems programming", C for stack overflows).

So apart from a distinct component, the AI agent also provides context for the utility of the language element of this system.

The "AI agent" container component of this system is agnostic to the sort of "AI" within the agent. The agent interface is an abstraction of communication with the agent. Agents may communicate with each other, with tools, and with the environment.

It is possible for a person to "inhabit" an agent to participate in the world and communicate with other agents. This uniformity of agents containing intelligence clarifies and simplifies the architecture without loss of generality.

### Necessary Attributes of (Ideal) Agents

The goal is to experimentally create real intelligence, where learning, understanding, and sense-making transfer to new domains with ever-improving accuracy and power. This would contrast sharply with the current scheme, which has an inverse relationship between generality and accuracy (i.e. the more general, the less accurate inescapably).

The following are structural elements of agents, where they:

* **Inhabit a world**;
* Have a **"language interface" (expanded on in section 2 below) for input and output**;
* Have a **"language interface" to tools** (expanded on in section 3 below);
* Have an **operational (most likely "language") interface** to the world they exist within;
* **Produce telemetry** that is combined with the world and tool telemetry;
* Are able to **use the telemetry as feedback**.


Core functions or capabilities:

* **Embedded and located in a world with space-time**. This is essential to causality;
* **Sensorimotor capabilities** in the broadest sense. The ability to perceive and act;
* **Intentionality**, acting in pursuit of a goal;
* **Boredom**, essentially an internal state of insufficient novelty in recent experience;
* **Curiosity**, and urge to question and pursue "What would happen if...?"
* **Learning not training**, may be externally (goals provided) or internally (curiosity) guided;
* **Understanding**, closes the loop between perception, learning, intentionality, acting;

* **Purpose**, these are individual, internal
* **Goals**, these are external and can be collective, must be multiple and often will be in conflict
* **Motivation**, the direction of attention and energy toward a goal
* **Drive**, a force moving foward

The concepts of perception, goals, causality, etc are used in the most general sense. An agent could "intend to find the error in a piece of code by understanding the looping structure where the error is happening and trying changes, potentially, but hopefully not exclusively at random".

All of these concepts should be vigorously de-anthropomorphized.

[Dynamic Field Theory](https://dynamicfieldtheory.org) has already established quite substantial progress on many of these but it appears to lack good surrounding infrastructure.

### Assertions

After rather extensive review of the current state of knowledge in the general domain of machine intelligence, these things seem indisputable:

1. LLMs are a dead end.
1. The mathematics of intelligence is not gradient descent or linear algebra.
1. The computational resource for intelligence is not GPUs.
1. There is a vast amount of knowledge about what constitutes machine intelligence, but because of a combination of the following, progress has been restricted:
    1. The complexity of the field;
    1. The layering of concepts (i.e. no simple reduction to "it's turtles all the way down");
    1. The inherently cross-disciplinary nature of intelligence but lack of cross-disciplinary teams;
    1. The fact that there is no 10-year or less unicorns possible (or haven't been to this point) driving VC hype-trains;
    1. There is precious little funding for actual plausible machine intelligence work outside of academic institutions or the random contrarian like Jeff Hawkins who self-funds.

Despite this, real machine intelligence is both possible and plausible in the relatively near future. It will start much less complex than has been imagined (ie we don't need brain-level numbers of connected components), and will progress in an intuitive way (i.e. ascending levels of intelligence capabilities).

#### Plausible Machine Intelligence Is Much More Realistic Than It May Appear

There are well-established AI research efforts and AI models that contrast quite significantly with the current dominant LLM model:

* [Thousand Brains Project]()
* [Integrated Neuro-Symbolic Architecture]()
* [Dynamic Field Theory](https://dynamicfieldtheory.org) has already established quite substantial progress on many of these but it appears to lack good surrounding infrastructure.

### So What?

The AI agent component is key to decoupling from the existing dominant paradigm but still being able to use and evaluate it, while seamlessly incorporating various other research paradigms, including our own.

The AI agent also is central to being able to distribute training, evolution, and usage across consumer-grade mobile devices, tablets, and laptops.

### Pitch

The AI agent allows for immediately integrating and leveraging existing systems, like LLMs (whether local models or an API service) within the context of all the other components. It enables 0-60 in attention-getting seconds.

But it also immediately standardizes the interface for inter-operating with other models, some well established in academic research but virtually unheard of in industry.

It usefully separates the concept of machine intelligence from tools and from infrastructure (ie computation resources and their configuration). This decoupling seeds collaboration across disparate ecosystems (e.g. a proof assistant project is unlikely to be interested in particular AI models or AI infrastructure) with little cost.


#### Causality... OR What the Hell Were We Thinking?

**ALL** of science can be reduced to an attempt to create a good explanation for the causality **we experience**. We're not making it up. It's "out there". Everything we try to understand is a manifestation *of the universe*. Stars, cancer, water, electromagnetic phenomena, human intelligence, cognition, biases, beliefs, political parties, animals, bacteria, viruses, etc. etc. etc. It's all in the universe.

How in the hell did we think we could create a machine intelligence that knows nothing of causality? Why would we ever think that a tool that does not understand causality would be useful?

Causality happens in space-time. Why would we ever think we could create a machine intelligence that does not operate within or understand anything about space-time?

It's lunacy!


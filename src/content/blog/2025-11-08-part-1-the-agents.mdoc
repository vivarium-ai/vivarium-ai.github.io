---
title: "Part 1: The Agents"
author: Brian Shirai
date: 2025-11-08
order: 1
---

Posts in this series:

* [The Vivarium AI Experimentation Platform](/blog/2025-11-08-the-vivarium-ai-experimentation-platform/)
* [Part 1: The Agents](/blog/2025-11-08-part-1-the-agents/)
* [Part 2: The Languages](/blog/2025-11-08-part-2-the-languages/)
* [Part 3: The Tools](/blog/2025-11-08-part-3-the-tools/)
* [Part 4: The Infrastructure](/blog/2025-11-08-part-4-the-infrastructure/)
* [Part 5: The Roadmap](/blog/2025-11-08-part-5-the-roadmap/)
* [Part 6: The Funding](/blog/2025-11-08-part-6-the-funding/)

## AI Agents

Artificial machine intelligence, and indeed, artificial "general" intelligence,
is the core concept that binds the rest of these efforts.

In Vivarium, the "agent" is a container for an intelligence. It forms the
boundary through which the agent interacts with the world.

As such, the agent concept is agnostic to what form that intelligence may take.
In fact, the way a human interacts with the Vivarium system "from the inside"
is via an agent proxy.

In this way, an agent in Vivarium can immediately be implemented using an
existing LLM API.

But because the agent concept is agnostic about what intelligence it contains,
it provides a key capability to decoupling from the existing dominant LLM
paradigm but still being able to use and evaluate it, while seamlessly
incorporating various other research paradigms, including our own.

The AI agent also is central to being able to distribute training, evolution,
and usage across consumer-grade mobile devices, tablets, and laptops. This
enables the location for the compute of the agent to be separated from the
computing device providing the resource under the rest of the Vivarium
instance.

### How to Think About the Languge Interface

The language and language-related tools (e.g. the compiler assembly, including
the JIT machinery) are obviously useful in a stand-alone manner because
languages and compilers have been used to build many kinds of applications.

But since general purpose languages are so useful, most programmers don't
consider language tools to be that useful. They have something "good enough" in
the general purpose language they use for primarily the domain they work with
(roughly: Ruby for webapps, Python for data science, numerical computing, and
AI models, Go for networked distributed systems, Rust for "systems
programming", C for stack overflows).

So apart from a distinct component, the AI agent also provides context for the
utility of the language element of this system.

The "AI agent" container component of this system is agnostic to the sort of
"AI" within the agent. The agent interface is an abstraction of communication
with the agent. Agents may communicate with each other, with tools, and with
the environment.

It is possible for a person to "inhabit" an agent to participate in the world
and communicate with other agents. This uniformity of agents containing
intelligence clarifies and simplifies the architecture without loss of
generality.

### Necessary Attributes of (Ideal) Agents

The goal is to experimentally create real intelligence, where learning,
understanding, and sense-making transfer to new domains with ever-improving
accuracy and power. This would contrast sharply with the current scheme, which
has an inverse relationship between generality and accuracy (i.e. the more
general, the less accurate inescapably).

The following are structural elements of agents, where they:

* **Inhabit a world**;
* Have a **"language interface" (expanded on in section 2 below) for input and output**;
* Have a **"language interface" to tools** (expanded on in section 3 below);
* Have an **operational (most likely "language") interface** to the world they exist within;
* **Produce telemetry** that is combined with the world and tool telemetry;
* Are able to **use the telemetry as feedback**.

And these (or many of them) should be required core functions or capabilities:

* **Embedded and located in a world with space-time**. This is essential to causality;
* **Sensorimotor capabilities** in the broadest sense. The ability to perceive and act;
* **Intentionality**, acting in pursuit of a goal;
* **Boredom**, essentially an internal state of insufficient novelty in recent experience;
* **Curiosity**, and urge to question and pursue "What would happen if...?"
* **Purpose**, these are individual, internal
* **Goals**, these are external and can be collective, must be multiple and often will be in conflict
* **Motivation**, the direction of attention and energy toward a goal
* **Drive**, a force moving foward
* **Learning not training**, may be externally (goals provided) or internally (curiosity) guided;
* **Understanding**, closes the loop between perception, learning, intentionality, acting;

The concepts of perception, goals, causality, etc are used in the most general
sense. An agent could "intend to find the error in a piece of code by
understanding the looping structure where the error is happening and trying
changes, potentially, but hopefully not exclusively at random".

All of these concepts should be rigorounly defined and vigorously
de-anthropomorphized. This itself constitutes a significant amount of work on
the agent aspect of Vivarium.

[Dynamic Field Theory](https://dynamicfieldtheory.org) has already established
quite substantial progress on many of these but it appears to lack good
surrounding infrastructure.

### So What?

The AI agent component is key to decoupling from the existing dominant paradigm but still being able to use and evaluate it, while seamlessly incorporating various other research paradigms, including our own.

The AI agent also is central to being able to distribute training, evolution, and usage across consumer-grade mobile devices, tablets, and laptops.

### Pitch

The AI agent allows for immediately integrating and leveraging existing systems, like LLMs (whether local models or an API service) within the context of all the other components. It enables 0-60 in attention-getting seconds.

But it also immediately standardizes the interface for inter-operating with other models, some well established in academic research but virtually unheard of in industry.

It usefully separates the concept of machine intelligence from tools and from infrastructure (ie computation resources and their configuration). This decoupling seeds collaboration across disparate ecosystems (e.g. a proof assistant project is unlikely to be interested in particular AI models or AI infrastructure) with little cost.


#### Causality... OR What the Hell Were We Thinking?

**ALL** of science can be reduced to an attempt to create a good explanation for the causality **we experience**. We're not making it up. It's "out there". Everything we try to understand is a manifestation *of the universe*. Stars, cancer, water, electromagnetic phenomena, human intelligence, cognition, biases, beliefs, political parties, animals, bacteria, viruses, etc. etc. etc. It's all in the universe.

How in the hell did we think we could create a machine intelligence that knows nothing of causality? Why would we ever think that a tool that does not understand causality would be useful?

Causality happens in space-time. Why would we ever think we could create a machine intelligence that does not operate within or understand anything about space-time?

It's lunacy!

